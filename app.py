import streamlit as st
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

st.set_page_config(page_title="Multi Documents Summarization", layout="wide")

st.title("ðŸš€ Multi-Documents Summarization")
st.write("Fine-tuned Pegasus Transformer Model")

@st.cache_resource
def load_model():
    """Load model from Hugging Face Hub"""
    try:
        model = AutoModelForSeq2SeqLM.from_pretrained("google/pegasus-cnn_dailymail")
        tokenizer = AutoTokenizer.from_pretrained("google/pegasus-cnn_dailymail")
        return model, tokenizer
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None, None

def summarize_text(text, model, tokenizer):
    """Generate summary for a single text"""
    inputs = tokenizer(text, return_tensors="pt", max_length=1024, truncation=True)
    summary_ids = model.generate(
        inputs["input_ids"],
        max_length=150,
        num_beams=4,
        early_stopping=True
    )
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary.replace("<n>", "\n")

model, tokenizer = load_model()

if model is None:
    st.error("Could not load model. Please check your internet connection.")
else:
    st.success("âœ… Model loaded successfully!")
    
    # Tabs for different input methods
    tab1, tab2 = st.tabs(["ðŸ“ Multiple Text Inputs", "ðŸ“„ File Upload"])
    
    with tab1:
        st.write("**Enter multiple documents below (one per box):**")
        
        # Initialize session state for documents
        if 'num_docs' not in st.session_state:
            st.session_state.num_docs = 2
        
        # Add/Remove document buttons
        col1, col2 = st.columns([1, 5])
        with col1:
            if st.button("âž• Add Document"):
                st.session_state.num_docs += 1
        with col2:
            if st.button("âž– Remove Document") and st.session_state.num_docs > 1:
                st.session_state.num_docs -= 1
        
        # Multiple text inputs
        documents = []
        for i in range(st.session_state.num_docs):
            doc = st.text_area(
                f"Document {i+1}:", 
                height=150, 
                key=f"doc_{i}",
                placeholder=f"Paste document {i+1} here..."
            )
            if doc.strip():
                documents.append(doc)
        
        # Summary type selection
        summary_type = st.radio(
            "Summary Type:",
            ["Combined Summary", "Individual Summaries"],
            horizontal=True
        )
        
        if documents and st.button("ðŸš€ Generate Summary", key="text_summary"):
            with st.spinner("Generating summary..."):
                try:
                    if summary_type == "Combined Summary":
                        # Combine all documents
                        combined_text = "\n\n".join(documents)
                        summary = summarize_text(combined_text, model, tokenizer)
                        
                        st.success("âœ… Summary Generated!")
                        st.markdown("### ðŸ“‹ Combined Summary")
                        st.info(summary)
                        
                    else:  # Individual Summaries
                        st.success("âœ… Summaries Generated!")
                        for idx, doc in enumerate(documents, 1):
                            summary = summarize_text(doc, model, tokenizer)
                            st.markdown(f"### ðŸ“„ Document {idx} Summary")
                            st.info(summary)
                            st.divider()
                            
                except Exception as e:
                    st.error(f"Error generating summary: {e}")
    
    with tab2:
        st.write("**Upload text files (.txt) for summarization:**")
        
        uploaded_files = st.file_uploader(
            "Choose files", 
            type=['txt'], 
            accept_multiple_files=True
        )
        
        if uploaded_files:
            st.write(f"**{len(uploaded_files)} file(s) uploaded**")
            
            file_summary_type = st.radio(
                "Summary Type:",
                ["Combined Summary", "Individual Summaries"],
                horizontal=True,
                key="file_summary_type"
            )
            
            if st.button("ðŸš€ Generate Summary", key="file_summary"):
                with st.spinner("Processing files and generating summary..."):
                    try:
                        file_contents = []
                        for file in uploaded_files:
                            content = file.read().decode("utf-8")
                            file_contents.append(content)
                        
                        if file_summary_type == "Combined Summary":
                            combined_text = "\n\n".join(file_contents)
                            summary = summarize_text(combined_text, model, tokenizer)
                            
                            st.success("âœ… Summary Generated!")
                            st.markdown("### ðŸ“‹ Combined Summary")
                            st.info(summary)
                        else:
                            st.success("âœ… Summaries Generated!")
                            for idx, (file, content) in enumerate(zip(uploaded_files, file_contents), 1):
                                summary = summarize_text(content, model, tokenizer)
                                st.markdown(f"### ðŸ“„ {file.name}")
                                st.info(summary)
                                st.divider()
                                
                    except Exception as e:
                        st.error(f"Error processing files: {e}")
    
    # Model metrics
    st.divider()
    st.subheader("ðŸ“Š Model Performance Metrics")
    
    metrics = {
        "Pegasus (CNN/DailyMail)": {"ROUGE-1": 47.65, "ROUGE-2": 18.75, "ROUGE-L": 24.95},
        "TextRank": {"ROUGE-1": 43.83, "ROUGE-2": 7.97, "ROUGE-L": 34.13},
        "LSTM-Seq2Seq": {"ROUGE-1": 38.0, "ROUGE-2": 17.0, "ROUGE-L": 32.0}
    }
    
    st.json(metrics)
